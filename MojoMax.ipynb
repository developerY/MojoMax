{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPqCYRC8lJjEr6eEwFsKnZM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/developerY/MojoMax/blob/main/MojoMax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INR5nxgRj3bA"
      },
      "outputs": [],
      "source": [
        "!pip install modular --index-url https://dl.modular.com/public/nightly/python/simple/ --extra-index-url https://download.pytorch.org/whl/cpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "8KLTegwJqsUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from max.driver import CPU, Accelerator, Tensor, accelerator_count\n",
        "from max.dtype import DType\n",
        "from max.engine import InferenceSession\n",
        "from max.graph import DeviceRef, Graph, TensorType, ops"
      ],
      "metadata": {
        "id": "0jE1oNg7rACu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accelerator_count()"
      ],
      "metadata": {
        "id": "2pltftEJrKIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = CPU() if accelerator_count() == 0 else Accelerator()\n",
        "device"
      ],
      "metadata": {
        "id": "sZck1H90rPwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_width = 10\n",
        "dtype = DType.float32\n",
        "\n",
        "with Graph(\n",
        "    \"vector_addition\",\n",
        "    input_types=[\n",
        "        TensorType(\n",
        "            dtype,\n",
        "            shape=[vector_width],\n",
        "            device=DeviceRef.from_device(device),\n",
        "        ),\n",
        "        TensorType(\n",
        "            dtype,\n",
        "            shape=[vector_width],\n",
        "            device=DeviceRef.from_device(device),\n",
        "        ),\n",
        "    ],\n",
        ") as graph:\n",
        "    lhs, rhs = graph.inputs\n",
        "    output = lhs + rhs\n",
        "    graph.output(output)"
      ],
      "metadata": {
        "id": "puZgX5XSraYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session = InferenceSession(\n",
        "    devices=[device],\n",
        ")\n",
        "\n",
        "model = session.load(graph)"
      ],
      "metadata": {
        "id": "q1BTtl7KrgYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lhs_values = np.random.uniform(size=(vector_width)).astype(np.float32)\n",
        "rhs_values = np.random.uniform(size=(vector_width)).astype(np.float32)\n",
        "\n",
        "lhs_tensor = Tensor.from_numpy(lhs_values).to(device)\n",
        "rhs_tensor = Tensor.from_numpy(rhs_values).to(device)"
      ],
      "metadata": {
        "id": "xRMLB4ifbPjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.execute(lhs_tensor, rhs_tensor)[0]\n",
        "\n",
        "result = result.to(CPU())"
      ],
      "metadata": {
        "id": "D8DXSehybTFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_QD15XwSr1Ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Left-hand-side values:\")\n",
        "print(lhs_values)\n",
        "print()\n",
        "\n",
        "print(\"Right-hand-side values:\")\n",
        "print(rhs_values)\n",
        "print()\n",
        "\n",
        "print(\"Graph result:\")\n",
        "print(result.to_numpy())\n",
        "print()\n",
        "\n",
        "print(\"Expected result:\")\n",
        "print(lhs_values + rhs_values)"
      ],
      "metadata": {
        "id": "GrgRlySWbVLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from max.entrypoints.llm import LLM\n",
        "from max.pipelines import PipelineConfig\n",
        "from max.serve.config import Settings"
      ],
      "metadata": {
        "id": "6xKaR7qaT_zE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
        "print(f\"Loading model: {model_path}\")\n",
        "pipeline_config = PipelineConfig(model_path=model_path)\n",
        "settings = Settings()\n",
        "llm = LLM(settings, pipeline_config)\n",
        "\n",
        "prompts = [\n",
        "    \"The fastest way to learn python is\",\n",
        "]\n",
        "\n",
        "print(\"Generating responses...\")\n",
        "responses = llm.generate(prompts, max_new_tokens=50)\n",
        "\n",
        "for i, (prompt, response) in enumerate(zip(prompts, responses)):\n",
        "    print(f\"========== Response {i} ==========\")\n",
        "    print(prompt + response)\n",
        "    print()"
      ],
      "metadata": {
        "id": "w_h_arrjUie2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}